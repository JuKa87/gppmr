@Book{Cameron+Trivedi:2013,
  author = {A. Colin Cameron and Pravin K. Trivedi},
  title = {Regression Analysis of Count Data},
  year = {2013},
  edition = {2nd},
  publisher = {Cambridge University Press},
  address = {Cambridge},
}

@Book{Chambers+Hastie:1992,
  editor = {John M. Chambers and Trevor J. Hastie},
  title = {Statistical Models in \proglang{S}},
  publisher = {Chapman \& Hall},
  year = {1992},
  address = {London},
}

@Manual{Jackman:2015,
  title = {\pkg{pscl}: Classes and Methods for \proglang{R} Developed in the Political Science Computational Laboratory, Stanford University},
  author = {Simon Jackman},
  year = {2015},
  note = {\proglang{R} package version 1.4.9},
  url = {https://CRAN.R-project.org/package=pscl},
}

@Article{Mullahy:1986,
  author = {John Mullahy},
  title = {Specification and Testing of Some Modified Count Data Models},
  year = {1986},
  journal = {Journal of Econometrics},
  volume = {33},
  number = {3},
  pages = {341--365},
  doi = {10.1016/0304-4076(86)90002-3},
}

@Book{McCullagh+Nelder:1989,
  author = {Peter McCullagh and John A. Nelder},
  title = {Generalized Linear Models},
  edition = {2nd},
  year = {1989},
  publisher = {Chapman \& Hall},
  address = {London},
  doi = {10.1007/978-1-4899-3242-6},
}

@Manual{R,
  title = {\proglang{R}: {A} Language and Environment for Statistical Computing},
  author = {{\proglang{R} Core Team}},
  organization = {\proglang{R} Foundation for Statistical Computing},
  address = {Vienna, Austria},
  year = {2017},
  url = {https://www.R-project.org/},
}

@Article{Stasinopoulos+Rigby:2007,
  author = {D. Mikis Stasinopoulos and Robert A. Rigby},
  title = {Generalized Additive Models for Location Scale and Shape ({GAMLSS}) in \proglang{R}},
  journal = {Journal of Statistical Software},
  year = {2007},
  volume = {23},
  number = {7},
  pages = {1--46},
  doi = {10.18637/jss.v023.i07},
}

@Book{Venables+Ripley:2002,
  author = {William N. Venables and Brian D. Ripley},
  title = {Modern Applied Statistics with \proglang{S}},
  edition = {4th},
  year = {2002},
  pages = {495},
  publisher = {Springer-Verlag},
  address = {New York},
  doi = {10.1007/978-0-387-21706-2},
}

@Book{Wood:2006,
  author = {Simon N. Wood},
  title = {Generalized Additive Models: An Introduction with \proglang{R}},
  year = {2006},
  publisher = {Chapman \& Hall/CRC},
  address = {Boca Raton},
}

@Article{Yee:2009,
  author = {Thomas W. Yee},
  title = {The \pkg{VGAM} Package for Categorical Data Analysis},
  journal = {Journal of Statistical Software},
  year = {2010},
  volume = {32},
  number = {10},
  pages = {1--34},
  doi = {10.18637/jss.v032.i10},
}

@Article{Zeileis+Kleiber+Jackman:2008,
  author = {Achim Zeileis and Christian Kleiber and Simon Jackman},
  title = {Regression Models for Count Data in \proglang{R}},
  journal = {Journal of Statistical Software},
  year = {2008},
  volume = {27},
  number = {8},
  pages = {1--25},
  doi = {10.18637/jss.v027.i08},
}


@article{cohen_multiple_1968,
	title = {Multiple regression as a general data-analytic system},
	volume = {70},
	copyright = {(c) 2012 APA, all rights reserved},
	issn = {1939-1455(Electronic);0033-2909(Print)},
	doi = {10.1037/h0026714},
	abstract = {Presents techniques for using multiple regression (MR) as a general variance-accounting procedure of great flexibility, power, and fidelity to research aims in both manipulative and observational psychological research. The identity of MR and fixed-model analysis of variance/covariance (AV/ACV) is sketched. This requires an exposition of means of expressing nominal scale (qualitative) data as independent variables in MR. Attention is given to methods for handling interactions, curvilinearity, missing data, and covariates, for either uncorrelated or correlated independent variables in MR. The relative roles of AV/ACV and MR in data analysis are described, and the practical advantages of the latter are set forth. (16 ref.)},
	number = {6, Pt.1},
	journal = {Psychological Bulletin},
	author = {Cohen, Jacob},
	year = {1968},
	keywords = {Statistical analysis},
	pages = {426--443},
	file = {APA Psycnet Fulltext PDF:/Users/karchjd/mystuff/others/papers/zotero/storage/8VV6MIHJ/Cohen - 1968 - Multiple regression as a general data-analytic sys.pdf:application/pdf}
}

@book{hamilton_time_1994,
	address = {Princeton, N.J},
	edition = {1st ed.},
	title = {Time series analysis},
	isbn = {978-0-691-04289-3},
	abstract = {The last decade has brought dramatic changes in the way that researchers analyze economic and financial time series. This book synthesizes these recent advances and makes them accessible to first-year graduate students. James Hamilton provides the first adequate text-book treatments of important innovations such as vector autoregressions, generalized method of moments, the economic and statistical consequences of unit roots, time-varying variances, and nonlinear time series models. In addition, he presents basic tools for analyzing dynamic systems (including linear representations, autocovariance generating functions, spectral analysis, and the Kalman filter) in a way that integrates economic theory with the practical difficulties of analyzing and interpreting real-world data. Time Series Analysis fills an important need for a textbook that integrates economic theory, econometrics, and new results. The book is intended to provide students and researchers with a self-contained survey of time series analysis. It starts from first principles and should be readily accessible to any beginning graduate student, while it is also intended to serve as a reference book for researchers.},
	language = {English},
	publisher = {Princeton University Press},
	author = {Hamilton, James Douglas},
	month = jan,
	year = {1994},
	file = {James Douglas Hamilton Time Series Analysis  1994.pdf:/Users/karchjd/mystuff/others/papers/zotero/storage/WTX5VAQX/James Douglas Hamilton Time Series Analysis  1994.pdf:application/pdf}
}

@book{bollen_structural_1989,
	address = {New York, NY},
	edition = {1st ed.},
	title = {Structural equations with latent variables},
	isbn = {978-0-471-01171-2},
	abstract = {Analysis of Ordinal Categorical Data Alan Agresti Statistical Science Now has its first coordinated manual of methods for analyzing ordered categorical data. This book discusses specialized models that, unlike standard methods underlying nominal categorical data, efficiently use the information on ordering. It begins with an introduction to basic descriptive and inferential methods for categorical data, and then gives thorough coverage of the most current developments, such as loglinear and logit models for ordinal data. Special emphasis is placed on interpretation and application of methods and contains an integrated comparison of the available strategies for analyzing ordinal data. This is a case study work with illuminating examples taken from across the wide spectrum of ordinal categorical applications. 1984 (0 471-89055-3) 287 pp. Regression Diagnostics Identifying Influential Data and Sources of Collinearity David A. Belsley, Edwin Kuh and Roy E. Welsch This book provides the practicing statistician and econometrician with new tools for assessing the quality and reliability of regression estimates. Diagnostic techniques are developed that aid in the systematic location of data points that are either unusual or inordinately influential; measure the presence and intensity of collinear relations among the regression data and help to identify the variables involved in each; and pinpoint the estimated coefficients that are potentially most adversely affected. The primary emphasis of these contributions is on diagnostics, but suggestions for remedial action are given and illustrated. 1980 (0 471-05856-4) 292 pp. Applied Regression Analysis Second Edition Norman Draper and Harry Smith Featuring a significant expansion of material reflecting recent advances, here is a complete and up-to-date introduction to the fundamentals of regression analysis, focusing on understanding the latest concepts and applications of these methods. The authors thoroughly explore the fitting and checking of both linear and nonlinear regression models, using small or large data sets and pocket or high-speed computing equipment. Features added to this Second Edition include the practical implications of linear regression; the Durbin-Watson test for serial correlation; families of transformations; inverse, ridge, latent root and robust regression; and nonlinear growth models. Includes many new exercises and worked examples. 1981 (0 471-02995-5) 709 pp.},
	language = {Englisch},
	publisher = {Wiley},
	author = {Bollen, Kenneth A.},
	year = {1989}
}

@book{raudenbush_hierarchical_2001,
	address = {Thousand Oaks, CA},
	edition = {2},
	title = {Hierarchical linear models: {Applications} and data analysis methods},
	isbn = {978-0-7619-1904-9},
	abstract = {Popular in its first edition for its rich, illustrative examples and lucid explanations of the theory and use of hierarchical linear models (HLM), the book has been updated to include: an intuitive introductory summary of the basic procedures for estimation and inference used with HLM models that only requires a minimal level of mathematical sophistication; a new section on multivariate growth models; a discussion of research synthesis or meta-analysis applications; aata analytic advice on centering of level-1 predictors, and new material on plausible value intervals and robust standard estimators.},
	language = {Englisch},
	publisher = {Sage},
	author = {Raudenbush, Stephen W. and Bryk, Anthony S.},
	year = {2001},
	file = {[Stephen_W._Raudenbush,_Anthony_S._Bryk]_Hierarchi(b-ok.org).pdf:/Users/karchjd/mystuff/others/papers/zotero/storage/53TGVCXU/[Stephen_W._Raudenbush,_Anthony_S._Bryk]_Hierarchi(b-ok.org).pdf:application/pdf}
}

@book{rasmussen_gaussian_2006,
	address = {Cambridge, MA},
	title = {Gaussian processes for machine learning},
	isbn = {978-0-262-18253-9},
	publisher = {MIT Press},
	author = {Rasmussen, Carl Edward and Williams, Christopher K. I.},
	year = {2006},
	keywords = {Machine learning, Gaussian processes, Data processing, Mathematical models},
	file = {RW6.pdf:/Users/karchjd/mystuff/others/papers/zotero/storage/5X3FRTBF/RW6.pdf:application/pdf}
}

@article{lee_maximum_2002,
	title = {Maximum likelihood estimation of nonlinear structural equation models},
	volume = {67},
	issn = {0033-3123, 1860-0980},
	url = {https://link.springer.com/article/10.1007/BF02294842},
	doi = {10.1007/BF02294842},
	abstract = {The existing maximum likelihood theory and its computer software in structural equation modeling are established based on linear relationships among manifest variables and latent variables. However, models with nonlinear relationships are often encountered in social and behavioral sciences. In this article, an EM type algorithm is developed for maximum likelihood estimation of a general nonlinear structural equation model. To avoid computation of the complicated multiple integrals involved, the E-step is completed by a Metropolis-Hastings algorithm. It is shown that the M-step can be completed efficiently by simple conditional maximization. Standard errors of the maximum likelihood estimates are obtained via Louis's formula. The methodology is illustrated with results from a simulation study and two real examples.},
	language = {en},
	number = {2},
	urldate = {2017-08-14},
	journal = {Psychometrika},
	author = {Lee, Sik-Yum and Zhu, Hong-Tu},
	month = jun,
	year = {2002},
	pages = {189--210},
	file = {Full Text PDF:/Users/karchjd/mystuff/others/papers/zotero/storage/IA5QIJ8M/Lee and Zhu - 2002 - Maximum likelihood estimation of nonlinear structu.pdf:application/pdf;Snapshot:/Users/karchjd/mystuff/others/papers/zotero/storage/A67IRGHE/BF02294842.html:text/html}
}


@phdthesis{karch_machine_2016,
	type = {Doctoral dissertation},
	title = {A machine learning perspective on repeated measures.},
	url = {https://edoc.hu-berlin.de/docviews/abstract.php?id=43051},
	urldate = {2017-06-02},
	school = {Humboldt-UniversitÃ€t zu Berlin, Lebenswissenschaftliche FakultÃ€t},
	author = {Karch, Julian D.},
	year = {2016},
	file = {Full Text PDF:/Users/karchjd/mystuff/others/papers/zotero/storage/F6EJCNZQ/Karch - 2016 - A machine learning perspective on repeated measure.pdf:application/pdf;Snapshot:/Users/karchjd/mystuff/others/papers/zotero/storage/BFQ8H7A7/abstract.html:text/html}
}

@article{zeileis_regression_2008,
	title = {Regression models for count data in {R}},
	volume = {27},
	number = {8},
	journal = {Journal of statistical software},
	author = {Zeileis, Achim and Kleiber, Christian and Jackman, Simon},
	year = {2008},
	pages = {1--25},
	file = {v27i08.pdf:/Users/karchjd/mystuff/others/papers/zotero/storage/LLQEZGEC/v27i08.pdf:application/pdf}
}

@book{diggle_analysis_1994,
	address = {Oxford : New York},
	series = {Oxford statistical science series},
	title = {Analysis of longitudinal data},
	isbn = {978-0-19-852284-3},
	number = {13},
	publisher = {Clarendon Press ; Oxford University Press},
	author = {Diggle, Peter and Liang, Kung-Yee and Zeger, Scott L.},
	year = {1994},
	keywords = {Statistical methods, Time-series analysis, Life sciences, Longitudinal method, Multivariate analysis},
	file = {v15i02.pdf:/Users/karchjd/mystuff/others/papers/zotero/storage/I7MGBXCA/v15i02.pdf:application/pdf}
}

@article{dray_ade4_2007,
	title = {The ade4 package: implementing the duality diagram for ecologists},
	volume = {22},
	shorttitle = {The ade4 package},
	number = {4},
	journal = {Journal of statistical software},
	author = {Dray, Stéphane and Dufour, Anne-Béatrice},
	year = {2007},
	pages = {1--20},
	file = {SD839.pdf:/Users/karchjd/mystuff/others/papers/zotero/storage/64R3XMTP/SD839.pdf:application/pdf}
}

@article{weeda_arf3ds4_2011,
	title = {\textbf{arf3DS4} : {An} {Integrated} {Framework} for {Localization} and {Connectivity} {Analysis} of {fMRI} {Data}},
	volume = {44},
	issn = {1548-7660},
	shorttitle = {\textbf{arf3DS4}},
	url = {http://www.jstatsoft.org/v44/i14/},
	doi = {10.18637/jss.v044.i14},
	abstract = {In standard fMRI analysis all voxels are tested in a massive univariate approach, that is, each voxel is tested independently. This requires stringent corrections for multiple comparisons to control the number of false positive tests (i.e., marking voxels as active while they are actually not). As a result, fMRI analyses may suﬀer from low power to detect activation, especially in studies with high levels of noise in the data, for example developmental or single-subject studies. Activated region ﬁtting (ARF) yields a solution by modeling fMRI data by multiple Gaussian shaped regions. ARF only requires a small number of parameters and therefore has increased power to detect activation. If required, the estimated regions can be directly used as regions of interest in a functional connectivity analysis. ARF is implemented in the R package arf3DS4. In this paper ARF and its implementation are described and illustrated with an example.},
	language = {en},
	number = {14},
	urldate = {2018-03-22},
	journal = {Journal of Statistical Software},
	author = {Weeda, Wouter D. and Vos, Frank de and Waldorp, Lourens J. and Grasman, Raoul P. P. P. and Huizenga, Hilde M.},
	year = {2011},
	file = {Weeda et al. - 2011 - barf3DS4b  An Integrated Framework for Local.pdf:/Users/karchjd/mystuff/others/papers/zotero/storage/L8M522BK/Weeda et al. - 2011 - barf3DS4b  An Integrated Framework for Local.pdf:application/pdf}
}

@article{brandmaier_pdc_2015,
	title = {\textbf{pdc} : {An} \textit{{R}} {Package} for {Complexity}-{Based} {Clustering} of {Time} {Series}},
	volume = {67},
	issn = {1548-7660},
	shorttitle = {\textbf{pdc}},
	url = {http://www.jstatsoft.org/v67/i05/},
	doi = {10.18637/jss.v067.i05},
	abstract = {Permutation distribution clustering is a complexity-based approach to clustering time series. The dissimilarity of time series is formalized as the squared Hellinger distance between the permutation distribution of embedded time series. The resulting distance measure has linear time complexity, is invariant to phase and monotonic transformations, and robust to outliers. A probabilistic interpretation allows the determination of the number of signiﬁcantly diﬀerent clusters. An entropy-based heuristic relieves the user of the need to choose the parameters of the underlying time-delayed embedding manually and, thus, makes it possible to regard the approach as parameter-free. This approach is illustrated with examples on empirical data.},
	language = {en},
	number = {5},
	urldate = {2018-03-22},
	journal = {Journal of Statistical Software},
	author = {Brandmaier, Andreas M.},
	year = {2015},
	file = {Brandmaier - 2015 - bpdcb  An iRi Package for Complexity-Ba.pdf:/Users/karchjd/mystuff/others/papers/zotero/storage/M3P2DJIL/Brandmaier - 2015 - bpdcb  An iRi Package for Complexity-Ba.pdf:application/pdf}
}

@article{driver_continuous_2017,
	title = {Continuous {Time} {Structural} {Equation} {Modeling} with \textit{{R}} {Package} \textbf{ctsem}},
	volume = {77},
	issn = {1548-7660},
	url = {http://www.jstatsoft.org/v77/i05/},
	doi = {10.18637/jss.v077.i05},
	abstract = {We introduce ctsem, an R package for continuous time structural equation modeling of panel (N {\textgreater} 1) and time series (N = 1) data, using full information maximum likelihood. Most dynamic models (e.g., cross-lagged panel models) in the social and behavioural sciences are discrete time models. An assumption of discrete time models is that time intervals between measurements are equal, and that all subjects were assessed at the same intervals. Violations of this assumption are often ignored due to the diﬃculty of accounting for varying time intervals, therefore parameter estimates can be biased and the time course of eﬀects becomes ambiguous. By using stochastic diﬀerential equations to estimate an underlying continuous process, continuous time models allow for any pattern of measurement occasions. By interfacing to OpenMx, ctsem combines the ﬂexible speciﬁcation of structural equation models with the enhanced data gathering opportunities and improved estimation of continuous time models. ctsem can estimate relationships over time for multiple latent processes, measured by multiple noisy indicators with varying time intervals between observations. Within and between eﬀects are estimated simultaneously by modeling both observed covariates and unobserved heterogeneity. Exogenous shocks with diﬀerent shapes, group diﬀerences, higher order diﬀusion eﬀects and oscillating processes can all be simply modeled. We ﬁrst introduce and deﬁne continuous time models, then show how to specify and estimate a range of continuous time models using ctsem.},
	language = {en},
	number = {5},
	urldate = {2018-03-22},
	journal = {Journal of Statistical Software},
	author = {Driver, Charles C. and Oud, Johan H. L. and Voelkle, Manuel C.},
	year = {2017},
	file = {Driver et al. - 2017 - Continuous Time Structural Equation Modeling with .pdf:/Users/karchjd/mystuff/others/papers/zotero/storage/M4ZI3JNQ/Driver et al. - 2017 - Continuous Time Structural Equation Modeling with .pdf:application/pdf}
}

@article{rosseel_lavaan_2012,
	title = {\textbf{lavaan} : {An} \textit{{R}} {Package} for {Structural} {Equation} {Modeling}},
	volume = {48},
	issn = {1548-7660},
	shorttitle = {\textbf{lavaan}},
	url = {http://www.jstatsoft.org/v48/i02/},
	doi = {10.18637/jss.v048.i02},
	abstract = {Structural equation modeling (SEM) is a vast ﬁeld and widely used by many applied researchers in the social and behavioral sciences. Over the years, many software packages for structural equation modeling have been developed, both free and commercial. However, perhaps the best state-of-the-art software packages in this ﬁeld are still closedsource and/or commercial. The R package lavaan has been developed to provide applied researchers, teachers, and statisticians, a free, fully open-source, but commercial-quality package for latent variable modeling. This paper explains the aims behind the development of the package, gives an overview of its most important features, and provides some examples to illustrate how lavaan works in practice.},
	language = {en},
	number = {2},
	urldate = {2018-03-22},
	journal = {Journal of Statistical Software},
	author = {Rosseel, Yves},
	year = {2012},
	file = {Rosseel - 2012 - blavaanb  An iRi Package for Structural.pdf:/Users/karchjd/mystuff/others/papers/zotero/storage/V9VXQD7G/Rosseel - 2012 - blavaanb  An iRi Package for Structural.pdf:application/pdf}
}

@article{bates_fitting_2015,
	title = {Fitting {Linear} {Mixed}-{Effects} {Models} {Using} \textbf{lme4}},
	volume = {67},
	issn = {1548-7660},
	url = {http://www.jstatsoft.org/v67/i01/},
	doi = {10.18637/jss.v067.i01},
	abstract = {Maximum likelihood or restricted maximum likelihood (REML) estimates of the parameters in linear mixed-eﬀects models can be determined using the lmer function in the lme4 package for R. As for most model-ﬁtting functions in R, the model is described in an lmer call by a formula, in this case including both ﬁxed- and random-eﬀects terms. The formula and data together determine a numerical representation of the model from which the proﬁled deviance or the proﬁled REML criterion can be evaluated as a function of some of the model parameters. The appropriate criterion is optimized, using one of the constrained optimization functions in R, to provide the parameter estimates. We describe the structure of the model, the steps in evaluating the proﬁled deviance or REML criterion, and the structure of classes or types that represents such a model. Suﬃcient detail is included to allow specialization of these structures by users who wish to write functions to ﬁt specialized linear mixed models, such as models incorporating pedigrees or smoothing splines, that are not easily expressible in the formula language used by lmer.},
	language = {en},
	number = {1},
	urldate = {2018-03-22},
	journal = {Journal of Statistical Software},
	author = {Bates, Douglas and Mächler, Martin and Bolker, Ben and Walker, Steve},
	year = {2015},
	file = {Bates et al. - 2015 - Fitting Linear Mixed-Effects Models Using blme4.pdf:/Users/karchjd/mystuff/others/papers/zotero/storage/SKU9LGWI/Bates et al. - 2015 - Fitting Linear Mixed-Effects Models Using blme4.pdf:application/pdf}
}
